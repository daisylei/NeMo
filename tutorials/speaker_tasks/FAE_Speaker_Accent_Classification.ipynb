{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Embeddings with TensorBoard Projector\n",
    "#### Task: Foreign Accent English classification\n",
    "#### Corpus: Common Voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import datetime\n",
    "import os\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from tqdm import tqdm\n",
    "from omegaconf import OmegaConf\n",
    "from nemo.collections.asr.models import EncDecSpeakerLabelModel\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "tf.io.gfile = tb.compat.tensorflow_stub.io.gfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants Definition\n",
    "* Model\n",
    "* Data manifests\n",
    "* Output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '/data1/nemo_experiments'\n",
    "EXP_DIR = f'{BASE_DIR}/220831-Finetune+Eval-CV-validated'\n",
    "EXP_DIR0 = f'{BASE_DIR}/220823-Finetune-CV-validated/220825-Finetune-CV-eval'\n",
    "LOG_DIR = f'{BASE_DIR}/tb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model_nemo_path = f'{BASE_DIR}/tb/Finetune-CV/2022-08-27_02-58-59/checkpoints/Finetune-CV.nemo'\n",
    "#\n",
    "# Data manifests\n",
    "eval_manifest_filepath = f'{EXP_DIR}/cv-self-manifest.json'\n",
    "\n",
    "eval0_manifest_filepath = f'{EXP_DIR0}/antonio_validated-reduced-resampled-eval_manifest.json'\n",
    "\n",
    "#\n",
    "# The problem with the data below is that the label space is different.\n",
    "#wcat_seg_manifest_filepath = f'{BASE_DIR}/WildcatDiapix/filelist_manifest-2.json'\n",
    "#wcat_all_manifest_filepath = f'{BASE_DIR}/WildcatDiapix/filelist_manifest.json'\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define In/Out filepaths\n",
    "# Select below as needed.\n",
    "#\n",
    "conf = OmegaConf.create()\n",
    "conf['data'] = {}\n",
    "# IN:\n",
    "conf.data['eval'] = dict(manifest_path=eval_manifest_filepath)\n",
    "conf.data.eval['title'] = \"%s\\n%s\" % ( model_nemo_path.replace(BASE_DIR+\"/\",\"\"),  os.path.basename( conf.data.eval.manifest_path ))\n",
    "#\n",
    "conf.data['eval0'] = dict(manifest_path=eval0_manifest_filepath)\n",
    "conf.data.eval0['title'] = \"%s\\n%s\" % ( model_nemo_path.replace(BASE_DIR+\"/\",\"\"),  os.path.basename( conf.data.eval0.manifest_path ))\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Step 1: Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-08-31 12:37:59 modelPT:149] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: nemo_experiments/220823-Finetune-CV-validated/220825-Finetune-CV-eval/antonio_validated-reduced-resampled-train_manifest.json\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - african\n",
      "    - australian\n",
      "    - canada\n",
      "    - england\n",
      "    - hongkong\n",
      "    - india\n",
      "    - ireland\n",
      "    - newzealand\n",
      "    - philippines\n",
      "    - scotland\n",
      "    - us\n",
      "    batch_size: 32\n",
      "    shuffle: true\n",
      "    augmentor:\n",
      "      speed:\n",
      "        prob: 0.5\n",
      "        sr: 16000\n",
      "        resample_type: kaiser_fast\n",
      "        min_speed_rate: 0.95\n",
      "        max_speed_rate: 1.05\n",
      "    \n",
      "[NeMo W 2022-08-31 12:37:59 modelPT:156] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: nemo_experiments/220823-Finetune-CV-validated/220825-Finetune-CV-eval/antonio_validated-reduced-resampled-dev_manifest.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 128\n",
      "    shuffle: false\n",
      "    \n",
      "[NeMo W 2022-08-31 12:37:59 modelPT:162] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: nemo_experiments/220823-Finetune-CV-validated/220825-Finetune-CV-eval/antonio_validated-reduced-resampled-eval_manifest.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 128\n",
      "    shuffle: false\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-08-31 12:37:59 features:200] PADDING: 16\n",
      "[NeMo I 2022-08-31 12:38:00 label_models:98] loss is Angular Softmax\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-08-31 12:38:00 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                    not been set for this class (TopKClassificationAccuracy). The property determines if `update` by\n",
      "                    default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                    achieved and we recommend setting this to `False`.\n",
      "                    We provide an checking function\n",
      "                    `from torchmetrics.utilities import check_forward_no_full_state`\n",
      "                    that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                    default for now) or if `full_state_update=False` can be used safely.\n",
      "                    \n",
      "      warnings.warn(*args, **kwargs)\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-08-31 12:38:00 save_restore_connector:243] Model EncDecSpeakerLabelModel was successfully restored from /data1/nemo_experiments/tb/Finetune-CV/2022-08-27_02-58-59/checkpoints/Finetune-CV.nemo.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load DNN.\n",
    "speaker_model = EncDecSpeakerLabelModel.restore_from(model_nemo_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Step 2: Extract Embeddings\n",
    "#### Evaluation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-08-31 12:38:13 collections:290] Filtered duration for loading collection is 0.000000.\n",
      "[NeMo I 2022-08-31 12:38:13 collections:294] # 24 files loaded accounting to # 2 labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 14.92it/s]\n"
     ]
    }
   ],
   "source": [
    "# STEP 2.1: Run Evaluation.\n",
    "# \n",
    "MANIFEST_FILEPATH = conf.data.eval.manifest_path\n",
    "#\n",
    "eval_embs, eval_logits, eval_ref_labels, eval_idx2labD = \\\n",
    "    EncDecSpeakerLabelModel.get_batch_embeddings(\n",
    "    speaker_model=speaker_model, \n",
    "    manifest_filepath=MANIFEST_FILEPATH, \n",
    "    batch_size=32, \n",
    "    sample_rate=16000, \n",
    "    device='cuda' )\n",
    "eval_embs = eval_embs / (np.linalg.norm(eval_embs, ord=2, axis=-1, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-08-31 12:39:03 collections:290] Filtered duration for loading collection is 0.000000.\n",
      "[NeMo I 2022-08-31 12:39:03 collections:294] # 2563 files loaded accounting to # 11 labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81/81 [00:05<00:00, 15.46it/s]\n"
     ]
    }
   ],
   "source": [
    "# STEP 2.1: Run Evaluation.\n",
    "# \n",
    "MANIFEST_FILEPATH = conf.data.eval0.manifest_path\n",
    "#\n",
    "eval0_embs, eval0_logits, eval0_ref_labels, eval0_idx2labD = \\\n",
    "    EncDecSpeakerLabelModel.get_batch_embeddings(\n",
    "    speaker_model=speaker_model, \n",
    "    manifest_filepath=MANIFEST_FILEPATH, \n",
    "    batch_size=32, \n",
    "    sample_rate=16000, \n",
    "    device='cuda' )\n",
    "eval0_embs = eval0_embs / (np.linalg.norm(eval0_embs, ord=2, axis=-1, keepdims=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "### Step 4: Visualization of the Embedding Space\n",
    "#### TensorBoard Projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch this to True if you really want to create a new entry in TB.\n",
    "WRITE2TB = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Eval Data Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather vector data\n",
    "vectors = eval_embs\n",
    "metadata = [ eval_idx2labD[x] for x in eval_ref_labels ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 24 embeddings in a 192-dim space.\n"
     ]
    }
   ],
   "source": [
    "# Create SummaryWritter\n",
    "logdir = f'{LOG_DIR}/SelfEmbsEvalCV_{datetime.datetime.now().isoformat()}'.replace(':','-')\n",
    "if WRITE2TB:\n",
    "    writer = SummaryWriter(logdir)\n",
    "    writer = SummaryWriter(logdir)\n",
    "    writer.add_embedding(vectors, metadata)\n",
    "    writer.close()\n",
    "print(f'Wrote {vectors.shape[0]} embeddings in a {vectors.shape[1]}-dim space.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "### Experimentsl (skip this part below).\n",
    "###### Trying to add more meta-data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "MANIFEST_FILEPATH = conf.data.eval.manifest_path\n",
    "manifestDF = pd.read_json(MANIFEST_FILEPATH, lines=True)\n",
    "manifestDF['path'] = manifestDF.audio_filepath.apply(lambda x : x.split(\"/\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "origMetaDF = pd.read_csv(f\"{BASE_DIR}/220831-Finetune+Eval-CV-validated/CV-self-recordings/data.tsv\", sep=',')\n",
    "#origMetaDF\n",
    "#origMetaDF.columns=['client_id', 'path', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accents', 'locale', 'segment', 'label']\n",
    "#\n",
    "_ = pd.merge(left=manifestDF, right=origMetaDF, how='left', on=['path', 'label'])\n",
    "_['speaker'] = _.client_id\n",
    "_['collection'] = 'iact'\n",
    "metadataLOL = _[['label', 'gender','age','speaker', 'sentence', 'collection']].values.tolist()\n",
    "#metadataLOL = manifestDF[['label', 'path']].values.tolist()\n",
    "#metadataLOL\n",
    "MANIFEST_FILEPATH = conf.data.eval0.manifest_path\n",
    "manifest0DF = pd.read_json(MANIFEST_FILEPATH, lines=True)\n",
    "manifest0DF['path'] = manifest0DF.audio_filepath.apply(lambda x : x.split(\"/\")[-1]).apply(lambda x : x.replace('.wav','.mp3'))\n",
    "\n",
    "origMeta0DF = pd.read_csv(f\"{BASE_DIR}/220823-Finetune-CV-validated/validated-label-dur.tsv\", sep='\\t', header=None)\n",
    "origMeta0DF.columns=['client_id', 'path', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accents', 'locale', 'segment', 'label', 'duration']\n",
    "#\n",
    "_ = pd.merge(left=manifest0DF, right=origMeta0DF, how='left', on=['path', 'label'])\n",
    "_['speaker'] = _.client_id.apply(lambda x : x[-4:])\n",
    "_['collection'] = 'mozilla'\n",
    "metadata0LOL = _[['label', 'gender','age','speaker', 'sentence', 'collection']].values.tolist()\n",
    "\n",
    "metadataLOL += metadata0LOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = np.concatenate((eval_embs,eval0_embs), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather vector data\n",
    "vectors = embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data1/nemo_experiments/tb/SelfEmbsEvalCV_2022-08-31T13-09-03.226288\n",
      "Wrote 2587 embeddings in a 192-dim space.\n"
     ]
    }
   ],
   "source": [
    "# Create SummaryWritter\n",
    "logdir = f'{LOG_DIR}/SelfEmbsEvalCV_{datetime.datetime.now().isoformat()}'.replace(':','-')\n",
    "WRITE2TB = True\n",
    "if WRITE2TB:\n",
    "    writer = SummaryWriter(logdir)\n",
    "    writer.add_embedding(vectors, metadataLOL, metadata_header=['label', 'gender','age','speaker', 'sentence', 'collection'], tag='SelfEmbsEvalCV')\n",
    "    writer.close()\n",
    "print(f'{logdir}\\nWrote {vectors.shape[0]} embeddings in a {vectors.shape[1]}-dim space.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
